{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828a9b48-c11e-49d9-8f7d-1f167c618ff9",
   "metadata": {},
   "source": [
    "## Case 01: Variational Autoencoder (VAE)\n",
    "* Dataset: CIFAR100\n",
    "* DL Framework: Tensorflow-Keras\n",
    "* DL Task: Image reconstruction\n",
    "\n",
    "`PREREQUISITE` All modules (with their suitable versions) are installed properly.\n",
    "<br>`TASK` Complete the notebook cell's code marked with <b>#TODO</b> comment.\n",
    "<br>`OBJECTIVE` Achieve a min. validation accuracy of <b>90%</b> within <b>10 epochs</b>.\n",
    "<br>`WARNING` Do <b>NOT</b> change any codes in the <i>config.ipynb</i> file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f08af-127c-49f9-9ccf-38dba84332ca",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b101e209-68f8-4d3b-9a6a-5aa9d05a1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.config import init, load_cifar_100_data, accuracy, show_reconstructions\n",
    "#TODO: please import other necessary libraries here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228afae-4fd2-4782-845d-e9597cf8f3e8",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8e7ec-e3df-4a03-b8ca-8f077a487421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train, _), (X_valid, _), (_, _) = load_cifar_100_data()\n",
    "print(X_train.shape, X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b3b20-da56-4a2e-8d7b-162d0775ef20",
   "metadata": {},
   "source": [
    "### Configure the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077376c-583e-44c4-b0a5-f667ddf9ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = init()[\"EPOCH\"] # DO NOT CHANGE THIS\n",
    "SEED = init()[\"SEED\"] # DO NOT CHANGE THIS\n",
    "BATCH_SIZE = ... #TODO: set hyperparameters (int)\n",
    "CODINGS_SIZE = ... #TODO: set parameters for the latent space representation (int)\n",
    "LEARNING_RATE = ... #TODO: set hyperparameters (int)\n",
    "IMG_SIZE = ... #TODO: define the image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07762cd-b5c8-4b6f-834e-a56d9d93ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "tf_random.set_seed(SEED) # for reproduciable results\n",
    "np_random.seed(SEED) # for reproduciable results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7303feb-9954-4199-8ad1-2fde822019a9",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7868a1-6a37-4794-a15f-8ebe04755573",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return K.random_normal(tf_shape(log_var)) * K.exp(log_var / 2) + mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef3cf7-baa4-419c-b6b0-01030115af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(i, c, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    function name:\n",
    "        encoder() = to compress the image inputs (latent)\n",
    "    function parameters:\n",
    "        i = image size\n",
    "        c = coding size\n",
    "    \"\"\"\n",
    "    inputs = keras.layers.Input(shape=i)\n",
    "    #TODO: define the layers stack for the encoder part. you may use MLP, LSTM, or CNN.\n",
    "    # variable 'z' will be the first layer\n",
    "    z = ...\n",
    "\n",
    "    codings_mean = keras.layers.Dense(c)(z)\n",
    "    codings_log_var = keras.layers.Dense(c)(z)\n",
    "    codings = Sampling()([codings_mean, codings_log_var])\n",
    "    return keras.models.Model(inputs=[inputs], outputs=[codings_mean, codings_log_var, codings]), inputs, codings_mean, codings_log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95db548-2ac7-4a6d-aeb0-db9a3e2ab85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(i, c, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    function name:\n",
    "        decoder = to reconstruct the image (with the same size) from the compressed version (latent)\n",
    "    function parameters:\n",
    "        i = image size\n",
    "        c = coding size\n",
    "    \"\"\"\n",
    "    decoder_inputs = keras.layers.Input(shape=[..., ..., c])\n",
    "    #TODO: define the layers stack for the decoder part. you may use MLP, LSTM, or CNN.\n",
    "    # variable 'x' will be the first layer\n",
    "    x = ...\n",
    "    \n",
    "    outputs = ...\n",
    "    return keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b3504-b319-4be0-b7ba-7c290d585367",
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_encoder, inputs, codings_mean, codings_log_var = encoder(i=IMG_SIZE, c=CODINGS_SIZE)\n",
    "variational_encoder.summary() # keep the trainable params below 20,000 is advised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6864ad-45c1-4ecc-9443-af3c811a7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_decoder = decoder(i=IMG_SIZE, c=CODINGS_SIZE)\n",
    "variational_decoder.summary() # keep the trainable params below 20,000 is advised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeff647-f148-4f6e-ae4f-3c068f4854dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, codings = variational_encoder(inputs)\n",
    "reconstructions = variational_decoder(codings)\n",
    "variational_ae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])\n",
    "latent_loss = -0.5 * K.sum(1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean), axis=-1)\n",
    "variational_ae.add_loss(K.mean(latent_loss) / (prod(IMG_SIZE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a965caa3-c962-42a1-939a-e2b114b4d408",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a590d5c-05b1-4ff6-b522-65cf5d7cde58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: define your loss function, optimizer, and metric\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e60108-558f-4fa3-8ee7-e7e8d988009f",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "* <b>Bechmark:</b> Validation accuracy fell at `91.48%` within 10 epochs.\n",
    "* If you encounter this `WARNING:tensorflow:AutoGraph ...` in the first epoch, please ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8b826-6400-4829-a0c3-25c40991f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = variational_ae.fit(X_train, X_train, epochs=EPOCH, batch_size=BATCH_SIZE, validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360bd97-14c8-483f-b517-4b2ede606767",
   "metadata": {},
   "source": [
    "### Visualize training and validation results\n",
    "\n",
    "Example output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d932e79d-5bbe-4c9a-bd46-e0d9751e1623",
   "metadata": {},
   "source": [
    "![VAE_acc_loss](img/vae_plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9cdb0-335c-4a22-8efd-74348f09fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: plot the loss and accuracy results from both training and validation, as depicted in the image above\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e079105-bee9-4c22-914f-50e86ddd5701",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad17ee-fbd6-4dfa-8772-b2821000baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_reconstructions(variational_ae, X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf80284-3dd9-4f00-a106-fdac434fb589",
   "metadata": {},
   "source": [
    "### Copyright 2022 PT. Agriaku Digital Indonesia\n",
    "* You may NOT use this file except there is written permission from AgriAku.\n",
    "* Any questions can be address to `nicholas.dominic@agriaku.com`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
